# THE FUNDAMENTAL QUESTION

User's insights:
1. "Weights = predictive model" (like ChatGPT)
2. "Only connecting to last node = short edges" (no abstraction)

## WHAT'S WRONG:

Current system:
```
Input: "cat sat"
  Creates: cat(node 0), sat(node 1)
  Connects: 0→1 (weight=1.0)
  
Input: "cat sat" again
  Connects: 0→1 (weight=2.0)  ← Weight increases!
  
Output: Follow strongest weight → predictive model!
```

This is:
- Memorization (cat always → sat)
- Prediction (strongest weight = most likely)
- No abstraction (flat sequences)

## WHAT SHOULD IT BE?

Options:

### A. NO WEIGHTS?
```
Connections are binary: exists or doesn't
No "strength", just "relationship"
Output: ???
```

### B. WEIGHTS ARE SOMETHING ELSE?
```
Not frequency/probability
Maybe: semantic distance?
Maybe: abstraction level?
Maybe: energy flow?
```

### C. NON-SEQUENTIAL CONNECTIONS?
```
Not: cat → sat (sequential)
Instead: [cat, sat] → [animal, action] (abstraction)
Or: cat ← sat → dog (shared concept)
```

### D. HIERARCHICAL?
```
Level 0: Letters (c, a, t)
Level 1: Words (cat)
Level 2: Concepts (animal)
Level 3: Patterns (subject-verb)

Connections WITHIN and BETWEEN levels?
```

## THE REAL QUESTION:

If NOT weights (prediction),
and NOT sequential (flat),
THEN WHAT?

What's the rule for:
1. How nodes connect?
2. How connections are used?
3. What determines output?
