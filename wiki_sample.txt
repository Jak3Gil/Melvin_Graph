{{Short description|Intelligence of machines}}
{{Redirect|AI|other uses|AI (disambiguation)|and|Artificial intelligence (disambiguation)}}<!-- related -->
{{Use dmy dates|date=October 2025}}{{Pp|small=yes}}<!-- details only a Wikipedian could love -->
{{Artificial intelligence}}<!-- portal -->

<!-- DEFINITIONS -->
'''Artificial intelligence''' ('''AI''') is the capability of [[computer|computational systems]] to perform tasks typically associated with [[human intelligence]], such as [[learning]], [[Reason|reasoning]], [[Problem solving|problem-solving]], [[perception]], and [[decision-making]]. It is a [[field of research]] in [[computer science]] that develops and studies methods and [[software]] that enable machines to [[machine perception|perceive their environment]] and use [[machine learning|learning]] and [[intelligence]] to take actions that maximize their chances of achieving defined goals.{{Sfnp|Russell|Norvig|2021|pp=1–4}}

<!-- APPLICATIONS -->
High-profile [[applications of AI]] include advanced [[web search engine]]s (e.g., [[Google Search]]); [[recommendation systems]] (used by [[YouTube]], [[Amazon (company)|Amazon]], and [[Netflix]]); [[virtual assistant]]s (e.g., [[Google Assistant]], [[Siri]], and [[Amazon Alexa|Alexa]]); [[autonomous vehicles]] (e.g., [[Waymo]]); [[Generative artificial intelligence|generative]] and [[Computational creativity|creative]] tools (e.g., [[language model]]s and [[AI art]]); and [[Superintelligence|superhuman]] play and analysis in [[strategy game]]s (e.g., [[chess]] and [[Go (game)|Go]]). However, many AI applications are not perceived as AI: "A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's [[AI effect|not labeled AI anymore]]."<ref>[http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/ AI set to exceed human brain power] {{Webarchive|url=https://web.archive.org/web/20080219001624/http://www.cnn.com/2006/TECH/science/07/24/ai.bostrom/|date=19 February 2008}} [[CNN.com]] (26 July 2006)</ref><ref>{{Cite journal |last1=Kaplan |first1=Andreas |last2=Haenlein |first2=Michael |date=2019 |title=Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence |journal=[[Business Horizons]] |volume=62 |pages=15–25 |doi=10.1016/j.bushor.2018.08.004 |issn=0007-6813 |s2cid=158433736}} [the question of the source is a pastiche of: ''[[Mirror#Literature|Snow White]]'']</ref>

<!-- GOALS AND TOOLS: SCOPE OF AI -->
Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, [[automated reasoning|reasoning]], [[knowledge representation]], [[Automated planning and scheduling|planning]], [[natural language processing]], [[Machine perception|perception]], and support for [[robotics]].{{Efn|name="Problems of AI"}} To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including [[state space search|search]] and [[mathematical optimization]], [[formal logic]], [[artificial neural network]]s, and methods based on [[statistics]], [[operations research]], and [[economics]].{{Efn|name="Tools of AI"}} AI also draws upon [[psychology]], [[linguistics]], [[Philosophy of artificial intelligence|philosophy]], [[neuroscience]], and other fields.<ref>{{Harvtxt|Russell|Norvig|2021|loc=§1.2}}.</ref> Some companies, such as [[OpenAI]], [[Google DeepMind]] and [[Meta Platforms|Meta]],<ref>{{Cite web |date=4 April 2024 |title=Tech companies want to build artificial general intelligence. But who decides when AGI is attained? |url=https://apnews.com/article/agi-artificial-general-intelligence-existential-risk-meta-openai-deepmind-science-ff5662a056d3cf3c5889a73e929e5a34 |access-date=20 May 2025 |website=[[AP News]] |language=en}}</ref> aim to create [[artificial general intelligence]] (AGI)—AI that can complete virtually any cognitive task at least as well as a human.

<!-- HISTORY AND ETHICS -->
Artificial intelligence was founded as an academic discipline in 1956,<ref name="Dartmouth workshop"/> and the field went through multiple cycles of optimism throughout [[History of artificial intelligence|its history]],<ref name="Succ1"/><ref name="Fund01"/> followed by periods of disappointment and loss of funding, known as [[AI winter]]s.<ref name="First AI Winter"/><ref name="Second AI Winter"/> Funding and interest vastly increased after 2012 when [[Graphics processing unit|graphics processing units]] started being used to accelerate neural networks and [[deep learning]] outperformed previous AI techniques.<ref name="Deep learning revolution"/> This growth accelerated further after 2017 with the [[transformer architecture]].{{Sfnp|Toews|2023}} In the 2020s, an ongoing period of rapid [[Progress in artificial intelligence|progress]] in advanced generative AI became known as the [[AI boom]]. Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raised [[Ethics of artificial intelligence|ethical concerns]] about [[AI aftermath scenarios|AI's long-term effects]] and [[Existential risk from artificial intelligence|potential existential risks]], prompting discussions about [[Regulation of artificial intelligence|regulatory policies]] to ensure [[AI safety|the safety]] and benefits of the technology.

== Goals ==
The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.{{Efn|name="Problems of AI"|This list of intelligent traits is based on the topics covered by the major AI textbooks, including: {{Harvtxt|Russell|Norvig|2021}}, {{Harvtxt|Luger|Stubblefield|2004}}, {{Harvtxt|Poole|Mackworth|Goebel|1998}} and {{Harvtxt|Nilsson|1998}}}}

=== Reasoning and problem-solving ===
Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical [[Deductive reasoning|deductions]].<ref>Problem-solving, puzzle solving, game playing, and deduction: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 3–5}}, {{Harvtxt|Russell|Norvig|2021|loc=chpt. 6}} ([[constraint satisfaction]]), {{Harvtxt|Poole|Mackworth|Goebel|1998|loc=chpt. 2, 3, 7, 9}}, {{Harvtxt|Luger|Stubblefield|2004|loc=chpt. 3, 4, 6, 8}}, {{Harvtxt|Nilsson|1998|loc=chpt. 7–12}}</ref> By the late 1980s and 1990s, methods were developed for dealing with [[uncertainty|uncertain]] or incomplete information, employing concepts from [[probability]] and [[economics]].<ref>Uncertain reasoning: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 12–18}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=345–395}}, {{Harvtxt|Luger|Stubblefield|2004|pp=333–381}}, {{Harvtxt|Nilsson|1998|loc=chpt. 7–12}}</ref>

Many of these algorithms are insufficient for solving large reasoning problems because they experience a "combinatorial explosion": They become exponentially slower as the problems grow.<ref name="Intractability and efficiency and the combinatorial explosion">[[Intractably|Intractability and efficiency]] and the [[combinatorial explosion]]: {{Harvtxt|Russell|Norvig|2021|p=21}}</ref> Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.<ref name="Psychological evidence of the prevalence of sub">Psychological evidence of the prevalence of sub-symbolic reasoning and knowledge: {{Harvtxt|Kahneman|2011}}, {{Harvtxt|Dreyfus|Dreyfus|1986}}, {{Harvtxt|Wason|Shapiro|1966}}, {{Harvtxt|Kahneman|Slovic|Tversky|1982}}</ref> Accurate and efficient reasoning is an unsolved problem.

=== Knowledge representation ===
[[File:General Formal Ontology.svg|thumb|upright=1.2|An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.]]

[[Knowledge representation]] and [[knowledge engineering]]<ref>[[Knowledge representation]] and [[knowledge engineering]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 10}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=23–46, 69–81, 169–233, 235–277, 281–298, 319–345}}, {{Harvtxt|Luger|Stubblefield|2004|pp=227–243}}, {{Harvtxt|Nilsson|1998|loc=chpt. 17.1–17.4, 18}}</ref> allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,{{Sfnp|Smoliar|Zhang|1994}} scene interpretation,{{Sfnp|Neumann|Möller|2008}} clinical decision support,{{Sfnp|Kuperman|Reichley|Bailey|2006}} knowledge discovery (mining "interesting" and actionable inferences from large [[database]]s),{{Sfnp|McGarry|2005}} and other areas.{{Sfnp|Bertini|Del Bimbo|Torniai|2006}}

A [[knowledge base]] is a body of knowledge represented in a form that can be used by a program. An [[ontology (information science)|ontology]] is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.{{Sfnp|Russell|Norvig|2021|pp=272}} Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;<ref>Representing categories and relations: [[Semantic network]]s, [[description logic]]s, [[Inheritance (object-oriented programming)|inheritance]] (including [[Frame (artificial intelligence)|frames]], and [[Scripts (artificial intelligence)|scripts]]): {{Harvtxt|Russell|Norvig|2021|loc=§10.2 & 10.5}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=174–177}}, {{Harvtxt|Luger|Stubblefield|2004|pp=248–258}}, {{Harvtxt|Nilsson|1998|loc=chpt. 18.3}}</ref> situations, events, states, and time;<ref>Representing events and time:[[Situation calculus]], [[event calculus]], [[fluent calculus]] (including solving the [[frame problem]]): {{Harvtxt|Russell|Norvig|2021|loc=§10.3}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=281–298}}, {{Harvtxt|Nilsson|1998|loc=chpt. 18.2}}</ref> causes and effects;<ref>[[Causality#Causal calculus|Causal calculus]]: {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=335–337}}</ref> knowledge about knowledge (what we know about what other people know);<ref>Representing knowledge about knowledge: Belief calculus, [[modal logic]]s: {{Harvtxt|Russell|Norvig|2021|loc=§10.4}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=275–277}}</ref> [[default reasoning]] (things that humans assume are true until they are told differently and will remain true even when other facts are changing);<ref name="Default reasoning">[[Default reasoning]], [[Frame problem]], [[default logic]], [[non-monotonic logic]]s, [[circumscription (logic)|circumscription]], [[closed world assumption]], [[abductive reasoning|abduction]]: {{Harvtxt|Russell|Norvig|2021|loc=§10.6}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=248–256, 323–335}}, {{Harvtxt|Luger|Stubblefield|2004|pp=335–363}}, {{Harvtxt|Nilsson|1998|loc=~18.3.3}}
(Poole ''et al.'' places abduction under "default reasoning". Luger ''et al.'' places this under "uncertain reasoning").</ref> and many other aspects and domains of knowledge.

Among the most difficult problems in knowledge representation are the breadth of [[Commonsense knowledge (artificial intelligence)|commonsense knowledge]] (the set of atomic facts that the average person knows is enormous);<ref name="Breadth of commonsense knowledge">Breadth of commonsense knowledge: {{Harvtxt|Lenat|Guha|1989|loc=Introduction}}, {{Harvtxt|Crevier|1993|pp=113–114}}, {{Harvtxt|Moravec|1988|p=13}}, {{Harvtxt|Russell|Norvig|2021|pp=241, 385, 982}} ([[qualification problem]])</ref> and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as "facts" or "statements" that they could express verbally).<ref name="Psychological evidence of the prevalence of sub"/> There is also the difficulty of [[knowledge acquisition]], the problem of obtaining knowledge for AI applications.{{Efn|It is among the reasons that [[expert system]]s proved to be inefficient for capturing knowledge.{{Sfnp|Newquist|1994|p=296}}{{Sfnp|Crevier|1993|pp=204–208}}}}

=== Planning and decision-making ===
An "agent" is anything that perceives and takes actions in the world. A [[rational agent]] has goals or preferences and takes actions to make them happen.{{Efn|
"Rational agent" is general term used in [[economics]], [[philosophy]] and theoretical artificial intelligence. It can refer to anything that directs its behavior to accomplish goals, such as a person, an animal, a corporation, a nation, or in the case of AI, a computer program.
}}{{Sfnp|Russell|Norvig|2021|p=528}} In [[automated planning]], the agent has a specific goal.<ref>[[Automated planning]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 11}}.</ref> In [[automated decision-making]], the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the "[[utility]]") that measures how much the agent prefers it. For each possible action, it can calculate the "[[expected utility]]": the [[utility]] of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.<ref>[[Automated decision making]], [[Decision theory]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 16–18}}.</ref>

In [[Automated planning and scheduling#classical planning|classical planning]], the agent knows exactly what the effect of any action will be.<ref>[[Automated planning and scheduling#classical planning|Classical planning]]: {{Harvtxt|Russell|Norvig|2021|loc=Section 11.2}}.</ref> In most real-world problems, however, the agent may not be certain about the situation they are in (it is "unknown" or "unobservable") and it may not know for certain what will happen after each possible action (it is not "deterministic"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.<ref>Sensorless or "conformant" planning, contingent planning, replanning (a.k.a. online planning): {{Harvtxt|Russell|Norvig|2021|loc=Section 11.5}}.</ref>

In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with [[inverse reinforcement learning]]), or the agent can seek information to improve its preferences.<ref>Uncertain preferences: {{Harvtxt|Russell|Norvig|2021|loc=Section 16.7}}
[[Inverse reinforcement learning]]: {{Harvtxt|Russell|Norvig|2021|loc=Section 22.6}}</ref> [[Information value theory]] can be used to weigh the value of exploratory or experimental actions.<ref>[[Information value theory]]: {{Harvtxt|Russell|Norvig|2021|loc=Section 16.6}}.</ref> The space of possible future actions and situations is typically [[intractably]] large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.

A [[Markov decision process]] has a [[Finite-state machine|transition model]] that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A [[Reinforcement learning#Policy|policy]] associates a decision with each possible state. The policy could be calculated (e.g., by [[policy iteration|iteration]]), be [[heuristic]], or it can be learned.<ref>[[Markov decision process]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 17}}.</ref>

[[Game theory]] describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.<ref>[[Game theory]] and multi-agent decision theory: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 18}}.</ref>

=== Learning ===
[[Machine learning]] is the study of programs that can improve their performance on a given task automatically.<ref>[[machine learning|Learning]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 19–22}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=397–438}}, {{Harvtxt|Luger|Stubblefield|2004|pp=385–542}}, {{Harvtxt|Nilsson|1998|loc=chpt. 3.3, 10.3, 17.5, 20}}</ref> It has been a part of AI from the beginning.{{Efn
|[[Alan Turing]] discussed the centrality of learning as early as 1950, in his classic paper "[[Computing Machinery and Intelligence]]".{{Sfnp|Turing|1950}} In 1956, at the original Dartmouth AI summer conference, [[Ray Solomonoff]] wrote a report on unsupervised probabilistic machine learning: "An Inductive Inference Machine".{{Sfnp|Solomonoff|1956}}
}}
[[File:Supervised and unsupervised learning.png|upright=1.4|thumb|In [[supervised learning]], the training data is labelled with the expected answers, while in [[unsupervised learning]], the model identifies patterns or structures in unlabelled data.]]
There are several kinds of machine learning. [[Unsupervised learning]] analyzes a stream of data and finds patterns and makes predictions without any other guidance.<ref>[[Unsupervised learning]]: {{Harvtxt|Russell|Norvig|2021|pp=653}} (definition), {{Harvtxt|Russell|Norvig|2021|pp=738–740}} ([[cluster analysis]]), {{Harvtxt|Russell|Norvig|2021|pp=846–860}} ([[word embedding]])</ref> [[Supervised learning]] requires labeling the training data with the expected answers, and comes in two main varieties: [[statistical classification|classification]] (where the program must learn to predict what category the input belongs in) and [[Regression analysis|regression]] (where the program must deduce a numeric function based on numeric input).<ref name="Supervised learning">[[Supervised learning]]: {{Harvtxt|Russell|Norvig|2021|loc=§19.2}} (Definition), {{Harvtxt|Russell|Norvig|2021|loc=Chpt. 19–20}} (Techniques)</ref>

In [[reinforcement learning]], the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as "good".<ref>[[Reinforcement learning]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 22}}, {{Harvtxt|Luger|Stubblefield|2004|pp=442–449}}</ref> [[Transfer learning]] is when the knowledge gained from one problem is applied to a new problem.<ref>[[Transfer learning]]: {{Harvtxt|Russell|Norvig|2021|pp=281}}, {{Harvtxt|The Economist|2016}}</ref> [[Deep learning]] is a type of machine learning that runs inputs through biologically inspired [[artificial neural networks]] for all of these types of learning.<ref>{{Cite web |title=Artificial Intelligence (AI): What Is AI and How Does It Work? {{!}} Built In |url=https://builtin.com/artificial-intelligence |access-date=30 October 2023 |website=builtin.com}}</ref>

[[Computational learning theory]] can assess learners by [[computational complexity]], by [[sample complexity]] (how much data is required), or by other notions of [[optimization]].<ref>[[Computational learning theory]]: {{Harvtxt|Russell|Norvig|2021|pp=672–674}}, {{Harvtxt|Jordan|Mitchell|2015}}</ref>

{{Clear}}

=== Natural language processing ===
<!-- This is linked to in the introduction -->
[[Natural language processing]] (NLP) allows programs to read, write and communicate in human languages.<ref>[[Natural language processing]] (NLP): {{Harvtxt|Russell|Norvig|2021|loc=chpt. 23–24}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=91–104}}, {{Harvtxt|Luger|Stubblefield|2004|pp=591–632}}</ref> Specific problems include [[speech recognition]], [[speech synthesis]], [[machine translation]], [[information extraction]], [[information retrieval]] and [[question answering]].<ref>Subproblems of [[Natural language processing|NLP]]: {{Harvtxt|Russell|Norvig|2021|pp=849–850}}</ref>

Early work, based on [[Noam Chomsky]]'s [[generative grammar]] and [[semantic network]]s, had difficulty with [[word-sense disambiguation]]{{Efn|See {{Section link|AI winter|Machine translation and the ALPAC report of 1966
}}}} unless restricted to small domains called "[[blocks world|micro-worlds]]" (due to the [[Commonsense knowledge (artificial intelligence)|common sense knowledge problem]]<ref name="Breadth of commonsense knowledge"/>). [[Margaret Masterman]] believed that it was meaning and not grammar that was the key to understanding languages, and that [[thesauri]] and not dictionaries should be the basis of computational language structure.

Modern deep learning techniques for NLP include [[word embedding]] (representing words, typically as [[Vector space|vectors]] encoding their meaning),{{Sfnp|Russell|Norvig|2021|pp=856–858}} [[transformer (machine learning model)|transformer]]s (a deep learning architecture using an [[Attention (machine learning)|attention]] mechanism),{{Sfnp|Dickson|2022}} and others.<ref>Modern statistical and deep learning approaches to [[Natural language processing|NLP]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 24}}, {{Harvtxt|Cambria|White|2014}}</ref> In 2019, [[generative pre-trained transformer]] (or "GPT") language models began to generate coherent text,{{Sfnp|Vincent|2019}}{{Sfnp|Russell|Norvig|2021|pp=875–878}} and by 2023, these models were able to get human-level scores on the [[bar exam]], [[SAT]] test, [[GRE]] test, and many other real-world applications.{{Sfnp|Bushwick|2023}}

=== Perception ===<!-- This is linked to in the introduction -->

[[Machine perception]] is the ability to use input from sensors (such as cameras, microphones, wireless signals, active [[lidar]], sonar, radar, and [[tactile sensor]]s) to deduce aspects of the world. [[Computer vision]] is the ability to analyze visual input.<ref>[[Computer vision]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 25}}, {{Harvtxt|Nilsson|1998|loc=chpt. 6}}</ref>

The field includes [[speech recognition]],{{Sfnp|Russell|Norvig|2021|pp=849–850}} [[image classification]],{{Sfnp|Russell|Norvig|2021|pp=895–899}} [[facial recognition system|facial recognition]], [[object recognition]],{{Sfnp|Russell|Norvig|2021|pp=899–901}} [[motion capture|object tracking]],{{Sfnp|Challa|Moreland|Mušicki|Evans|2011}} and [[robotic perception]].{{Sfnp|Russell|Norvig|2021|pp=931–938}}

=== Social intelligence ===
[[File:Kismet-IMG 6007-gradient.jpg|thumb|[[Kismet (robot)|Kismet]], a robot head which was made in the 1990s; it is a machine that can recognize and simulate emotions.{{Sfnp|MIT AIL|2014}}]]

[[Affective computing]] is a field that comprises systems that recognize, interpret, process, or simulate human [[Affect (psychology)|feeling, emotion, and mood]].<ref>[[Affective computing]]: {{Harvtxt|Thro|1993}}, {{Harvtxt|Edelson|1991}}, {{Harvtxt|Tao|Tan|2005}}, {{Harvtxt|Scassellati|2002}}</ref> For example, some [[virtual assistant]]s are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate [[human–computer interaction]].

However, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.{{Sfnp|Waddell|2018}} Moderate successes related to affective computing include textual [[sentiment analysis]] and, more recently, [[multimodal sentiment analysis]], wherein AI classifies the effects displayed by a videotaped subject.{{Sfnp|Poria|Cambria|Bajpai |Hussain|2017}}

=== General intelligence ===

A machine with [[artificial general intelligence]] would be able to solve a wide variety of problems with breadth and versatility similar to [[human intelligence]].<ref name="Artificial general intelligence" >
[[Artificial general intelligence]]: {{Harvtxt|Russell|Norvig|2021|pp=32–33, 1020–1021}}<br />Proposal for the modern version: {{Harvtxt|Pennachin|Goertzel|2007}}<br />Warnings of overspecialization in AI from leading researchers: {{Harvtxt|Nilsson|1995}}, {{Harvtxt|McCarthy|2007}}, {{Harvtxt|Beal|Winston|2009}}</ref>

== Techniques ==
AI research uses a wide variety of techniques to accomplish the goals above.{{Efn|name="Tools of AI"|This list of tools is based on the topics covered by the major AI textbooks, including: {{Harvtxt|Russell|Norvig|2021}}, {{Harvtxt|Luger|Stubblefield|2004}}, {{Harvtxt|Poole|Mackworth|Goebel|1998}} and {{Harvtxt|Nilsson|1998}}}}

=== Search and optimization ===
AI can solve many problems by intelligently searching through many possible solutions.<ref>[[Search algorithm]]s: {{Harvtxt|Russell|Norvig|2021|loc=chpts. 3–5}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=113–163}}, {{Harvtxt|Luger|Stubblefield|2004|pp=79–164, 193–219}}, {{Harvtxt|Nilsson|1998|loc=chpts. 7–12}}</ref> There are two very different kinds of search used in AI: [[state space search]] and [[Local search (optimization)|local search]].

==== State space search ====
[[State space search]] searches through a tree of possible states to try to find a goal state.<ref>[[State space search]]: {{Harvtxt|Russell|Norvig|2021|loc=chpt. 3}}</ref> For example, [[Automated planning and scheduling|planning]] algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called [[means-ends analysis]].{{Sfnp|Russell|Norvig|2021|loc=sect. 11.2}}

[[Brute force search|Simple exhaustive searches]]<ref>[[Uninformed search]]es ([[breadth first search]], [[depth-first search]] and general [[state space search]]): {{Harvtxt|Russell|Norvig|2021|loc=sect. 3.4}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=113–132}}, {{Harvtxt|Luger|Stubblefield|2004|pp=79–121}}, {{Harvtxt|Nilsson|1998|loc=chpt. 8}}</ref> are rarely sufficient for most real-world problems: the [[Search algorithm|search space]] (the number of places to search) quickly grows to [[Astronomically large|astronomical numbers]]. The result is a search that is [[Computation time|too slow]] or never completes.<ref name="Intractability and efficiency and the combinatorial explosion"/> "[[Heuristics]]" or "rules of thumb" can help prioritize choices that are more likely to reach a goal.<ref>[[Heuristic]] or informed searches (e.g., greedy [[Best-first search|best first]] and [[A* search algorithm|A*]]): {{Harvtxt|Russell|Norvig|2021|loc=sect. 3.5}}, {{Harvtxt|Poole|Mackworth|Goebel|1998|pp=132–147}}, {{Harvtxt|Poole|Mackworth|2017|loc=sect. 3.6}}, {{Harvtxt|Luger|Stubblefield|2004|pp=133–150}}</ref>

