# CURRENT LIMITS IN WORKING VERSION

From analysis:

## REMOVE THESE (Unnecessary):
1. Meta-nodes (21 nodes, ~400 lines of bootstrap code)
2. Hub detection (detect_hubs function, ~80 lines)
3. Pattern detection (detect_patterns function, ~120 lines)
4. Generalization test (test_generalization, ~50 lines)
5. Prediction system (predict_next, validate_predictions, ~100 lines)
6. Validation (validate_output_completeness, ~70 lines)
7. Compression reward functions (~50 lines)

= ~870 lines of unnecessary code!

## MAKE DYNAMIC:
1. node_cap: 10,000 → grow when 90% full
2. connection_cap: 100,000 → grow when 90% full
3. ngram_len: ≤10 → adaptive based on data
4. propagation hops: 5 → until convergence (state changes < 0.01)
5. learning_rate: 0.1 → adapt based on reuse ratio
6. decay_rate: 0.95 → adapt based on survival pressure

## CORE (Keep minimal):
- Nodes: token[64], state, energy, frequency
- Connections: src, dst, weight
- sense_input() - create/reuse + wire
- propagate() - signal transmission
- learn() - Hebbian strengthening
- emit_output() - follow rules
- apply_metabolism() - energy cost + death

= ~300 lines of essential code

TOTAL: 1660 lines → ~300 lines (80% reduction!)
